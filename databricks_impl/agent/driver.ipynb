{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -5015327496622565,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14b680d9-1a17-4bfd-913d-f6fb9d469fd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Tool-calling Agent\n",
    "\n",
    "This is an auto-generated notebook created by an AI playground export. In this notebook, you will:\n",
    "- Author a tool-calling [MLflow's `ResponsesAgent`](https://mlflow.org/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.ResponsesAgent) that uses the OpenAI client\n",
    "- Manually test the agent's output\n",
    "- Evaluate the agent with Mosaic AI Agent Evaluation\n",
    "- Log and deploy the agent\n",
    "\n",
    "This notebook should be run on serverless or a cluster with DBR<17.\n",
    "\n",
    " **_NOTE:_**  This notebook uses the OpenAI SDK, but AI Agent Framework is compatible with any agent authoring framework, including LlamaIndex or LangGraph. To learn more, see the [Authoring Agents](https://docs.databricks.com/generative-ai/agent-framework/author-agent) Databricks documentation.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Address all `TODO`s in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb887d2-5ca3-4e35-8636-7d1f44150d9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyter-server 1.23.4 requires anyio<4,>=3.1.0, but you have anyio 4.12.1 which is incompatible.\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -qqqq backoff databricks-openai uv databricks-agents mlflow-skinny[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -5015327496622565,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4419478f-8c4a-4189-a714-ab69426a5aab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the agent in code\n",
    "Below we define our agent code in a single cell, enabling us to easily write it to a local Python file for subsequent logging and deployment using the `%%writefile` magic command.\n",
    "\n",
    "For more examples of tools to add to your agent, see [docs](https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d64c4b2-4e5e-4664-9b0d-1f17e82b2fa8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 4"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agent.py\n",
    "import json\n",
    "from typing import Any, Callable, Generator, Optional\n",
    "from uuid import uuid4\n",
    "import warnings\n",
    "\n",
    "import backoff\n",
    "import mlflow\n",
    "import openai\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_openai import UCFunctionToolkit, VectorSearchRetrieverTool\n",
    "from mlflow.entities import SpanType, Document\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    "    output_to_responses_items_stream,\n",
    "    to_chat_completions_input,\n",
    ")\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from unitycatalog.ai.core.base import get_uc_function_client\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-gpt-5-mini\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"you are a helpful assistant, when prompted with a query search for related entries in the vector search. You report back with tables and datasets related to the user question.\"\"\"\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent, enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html\n",
    "###############################################################################\n",
    "class ToolInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    Class representing a tool for the agent.\n",
    "    - \"name\" (str): The name of the tool.\n",
    "    - \"spec\" (dict): JSON description of the tool (matches OpenAI Responses format)\n",
    "    - \"exec_fn\" (Callable): Function that implements the tool logic\n",
    "    - \"is_retriever\" (bool): Whether this tool is a retriever (for proper span typing)\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    spec: dict\n",
    "    exec_fn: Callable\n",
    "    is_retriever: bool = False\n",
    "\n",
    "\n",
    "def create_tool_info(tool_spec, exec_fn_param: Optional[Callable] = None, is_retriever: bool = False):\n",
    "    tool_spec[\"function\"].pop(\"strict\", None)\n",
    "    tool_name = tool_spec[\"function\"][\"name\"]\n",
    "    udf_name = tool_name.replace(\"__\", \".\")\n",
    "\n",
    "    # Define a wrapper that accepts kwargs for the UC tool call,\n",
    "    # then passes them to the UC tool execution client\n",
    "    def exec_fn(**kwargs):\n",
    "        function_result = uc_function_client.execute_function(udf_name, kwargs)\n",
    "        if function_result.error is not None:\n",
    "            return function_result.error\n",
    "        else:\n",
    "            return function_result.value\n",
    "    return ToolInfo(name=tool_name, spec=tool_spec, exec_fn=exec_fn_param or exec_fn, is_retriever=is_retriever)\n",
    "\n",
    "\n",
    "TOOL_INFOS = []\n",
    "\n",
    "# You can use UDFs in Unity Catalog as agent tools\n",
    "# TODO: Add additional tools\n",
    "UC_TOOL_NAMES = []\n",
    "\n",
    "uc_toolkit = UCFunctionToolkit(function_names=UC_TOOL_NAMES)\n",
    "uc_function_client = get_uc_function_client()\n",
    "for tool_spec in uc_toolkit.tools:\n",
    "    TOOL_INFOS.append(create_tool_info(tool_spec))\n",
    "\n",
    "\n",
    "# Use Databricks vector search indexes as tools\n",
    "# See [docs](https://docs.databricks.com/generative-ai/agent-framework/unstructured-retrieval-tools.html) for details\n",
    "\n",
    "# Use Databricks vector search indexes as tools\n",
    "# See the [Databricks Documentation](https://docs.databricks.com/generative-ai/agent-framework/unstructured-retrieval-tools.html) for details\n",
    "VECTOR_SEARCH_TOOLS = []\n",
    "VECTOR_SEARCH_TOOLS.append(\n",
    "        VectorSearchRetrieverTool(\n",
    "            index_name=\"jack_demos_classic.data_catalogue_demo.metadata_docs_index\",\n",
    "            # TODO: specify index description for better agent tool selection\n",
    "            # tool_description=\"\"\n",
    "        )\n",
    "    )\n",
    "for vs_tool in VECTOR_SEARCH_TOOLS:\n",
    "    TOOL_INFOS.append(create_tool_info(vs_tool.tool, vs_tool.execute, is_retriever=True))\n",
    "\n",
    "\n",
    "\n",
    "class ToolCallingAgent(ResponsesAgent):\n",
    "    \"\"\"\n",
    "    Class representing a tool-calling Agent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm_endpoint: str, tools: list[ToolInfo]):\n",
    "        \"\"\"Initializes the ToolCallingAgent with tools.\"\"\"\n",
    "        self.llm_endpoint = llm_endpoint\n",
    "        self.workspace_client = WorkspaceClient()\n",
    "        self.model_serving_client: OpenAI = (\n",
    "            self.workspace_client.serving_endpoints.get_open_ai_client()\n",
    "        )\n",
    "        self._tools_dict = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def get_tool_specs(self) -> list[dict]:\n",
    "        \"\"\"Returns tool specifications in the format OpenAI expects.\"\"\"\n",
    "        return [tool_info.spec for tool_info in self._tools_dict.values()]\n",
    "\n",
    "    def execute_tool(self, tool_name: str, args: dict) -> Any:\n",
    "        \"\"\"Executes the specified tool with the given arguments.\"\"\"\n",
    "        tool_info = self._tools_dict[tool_name]\n",
    "        \n",
    "        # Use RETRIEVER span for retrieval tools, TOOL span for others\n",
    "        span_type = SpanType.RETRIEVER if tool_info.is_retriever else SpanType.TOOL\n",
    "        \n",
    "        with mlflow.start_span(name=tool_name, span_type=span_type) as span:\n",
    "            result = tool_info.exec_fn(**args)\n",
    "            \n",
    "            # For retriever tools, set the retrieved documents as span outputs\n",
    "            if tool_info.is_retriever and result:\n",
    "                try:\n",
    "                    # Parse the result - VectorSearchRetrieverTool returns JSON string\n",
    "                    if isinstance(result, str):\n",
    "                        parsed_result = json.loads(result)\n",
    "                    else:\n",
    "                        parsed_result = result\n",
    "                    \n",
    "                    # Extract documents and convert to Document objects\n",
    "                    documents = []\n",
    "                    if isinstance(parsed_result, list):\n",
    "                        for doc in parsed_result:\n",
    "                            if isinstance(doc, dict):\n",
    "                                # Extract page_content and metadata\n",
    "                                page_content = doc.get(\"page_content\", doc.get(\"content\", doc.get(\"text\", str(doc))))\n",
    "                                metadata = doc.get(\"metadata\", {})\n",
    "                                doc_id = doc.get(\"id\")\n",
    "                                \n",
    "                                # Create Document object\n",
    "                                doc_obj = Document(\n",
    "                                    page_content=page_content,\n",
    "                                    metadata=metadata\n",
    "                                )\n",
    "                                if doc_id:\n",
    "                                    doc_obj.id = doc_id\n",
    "                                    \n",
    "                                documents.append(doc_obj)\n",
    "                    \n",
    "                    # Set documents as span outputs for RAG scorers\n",
    "                    if documents:\n",
    "                        span.set_outputs(documents)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    # If parsing fails, log but don't break the flow\n",
    "                    print(f\"Warning: Could not parse retriever results: {e}\")\n",
    "            \n",
    "            return result\n",
    "\n",
    "    def call_llm(self, messages: list[dict[str, Any]]) -> Generator[dict[str, Any], None, None]:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"PydanticSerializationUnexpectedValue\")\n",
    "            for chunk in self.model_serving_client.chat.completions.create(\n",
    "                model=self.llm_endpoint,\n",
    "                messages=to_chat_completions_input(messages),\n",
    "                tools=self.get_tool_specs(),\n",
    "                stream=True,\n",
    "            ):\n",
    "                chunk_dict = chunk.to_dict()\n",
    "                if len(chunk_dict.get(\"choices\", [])) > 0:\n",
    "                    yield chunk_dict\n",
    "\n",
    "    def handle_tool_call(\n",
    "        self,\n",
    "        tool_call: dict[str, Any],\n",
    "        messages: list[dict[str, Any]],\n",
    "    ) -> ResponsesAgentStreamEvent:\n",
    "        \"\"\"\n",
    "        Execute tool calls, add them to the running message history, and return a ResponsesStreamEvent w/ tool output\n",
    "        \"\"\"\n",
    "        try:\n",
    "            args = json.loads(tool_call.get(\"arguments\"))\n",
    "        except Exception as e:\n",
    "            args = {}\n",
    "        result = str(self.execute_tool(tool_name=tool_call[\"name\"], args=args))\n",
    "\n",
    "        tool_call_output = self.create_function_call_output_item(tool_call[\"call_id\"], result)\n",
    "        messages.append(tool_call_output)\n",
    "        return ResponsesAgentStreamEvent(type=\"response.output_item.done\", item=tool_call_output)\n",
    "\n",
    "    def call_and_run_tools(\n",
    "        self,\n",
    "        messages: list[dict[str, Any]],\n",
    "        max_iter: int = 10,\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        for _ in range(max_iter):\n",
    "            last_msg = messages[-1]\n",
    "            if last_msg.get(\"role\", None) == \"assistant\":\n",
    "                return\n",
    "            elif last_msg.get(\"type\", None) == \"function_call\":\n",
    "                yield self.handle_tool_call(last_msg, messages)\n",
    "            else:\n",
    "                yield from output_to_responses_items_stream(\n",
    "                    chunks=self.call_llm(messages), aggregator=messages\n",
    "                )\n",
    "\n",
    "        yield ResponsesAgentStreamEvent(\n",
    "            type=\"response.output_item.done\",\n",
    "            item=self.create_text_output_item(\"Max iterations reached. Stopping.\", str(uuid4())),\n",
    "        )\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        session_id = None\n",
    "        if request.custom_inputs and \"session_id\" in request.custom_inputs:\n",
    "            session_id = request.custom_inputs.get(\"session_id\")\n",
    "        elif request.context and request.context.conversation_id:\n",
    "            session_id = request.context.conversation_id\n",
    "\n",
    "        if session_id:\n",
    "            mlflow.update_current_trace(\n",
    "                metadata={\n",
    "                    \"mlflow.trace.session\": session_id,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(output=outputs, custom_outputs=request.custom_inputs)\n",
    "\n",
    "    def predict_stream(self, request: ResponsesAgentRequest) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        session_id = None\n",
    "        if request.custom_inputs and \"session_id\" in request.custom_inputs:\n",
    "            session_id = request.custom_inputs.get(\"session_id\")\n",
    "        elif request.context and request.context.conversation_id:\n",
    "            session_id = request.context.conversation_id\n",
    "\n",
    "        if session_id:\n",
    "            mlflow.update_current_trace(\n",
    "                metadata={\n",
    "                    \"mlflow.trace.session\": session_id,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        messages = to_chat_completions_input([i.model_dump() for i in request.input])\n",
    "        if SYSTEM_PROMPT:\n",
    "            messages.insert(0, {\"role\": \"system\", \"content\": SYSTEM_PROMPT})\n",
    "        yield from self.call_and_run_tools(messages=messages)\n",
    "\n",
    "\n",
    "# Log the model using MLflow\n",
    "mlflow.openai.autolog()\n",
    "AGENT = ToolCallingAgent(llm_endpoint=LLM_ENDPOINT_NAME, tools=TOOL_INFOS)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -5015327496622565,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b3e09bf-4ce2-45c4-894e-efeb9361c4c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output. Since we manually traced methods within `ResponsesAgent`, you can view the trace for each step the agent takes, with any LLM calls made via the OpenAI SDK automatically traced by autologging.\n",
    "\n",
    "Replace this placeholder input with an appropriate domain-specific example for your agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97a340be-1a90-45b1-9b3e-940fe59117e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8accaaa-545d-4bbc-9c77-9f7bd34ce8ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:717)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:460)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:591)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:62)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:62)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:62)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:62)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:569)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:851)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:877)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:876)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:931)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:724)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:175)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:201)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:201)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:172)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:148)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:23)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1027)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:947)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$8(ActivityContextFactory.scala:676)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:676)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:647)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:629)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:250)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:126)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:123)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:717)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:460)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:591)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:62)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:62)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:62)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:62)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:569)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:851)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:877)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:876)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:931)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:724)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:175)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:201)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:201)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:172)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:148)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:23)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1027)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:947)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$8(ActivityContextFactory.scala:676)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:676)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:647)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:629)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:250)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:273)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:269)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:126)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:123)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "AGENT.predict(\n",
    "    {\"input\": [{\"role\": \"user\", \"content\": \"what is 4*3 in python\"}], \"custom_inputs\": {\"session_id\": \"test-session-123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d2b7172-9936-4328-88a4-947219bb18e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'response.output_item.done', 'item': {'type': 'function_call', 'id': 'chatcmpl-D9OZUGcu9WpLG0FVAIbPAN0oHiFlj', 'call_id': 'call_oeVGufSLXyLhy2TWunj8LuIz', 'name': 'jack_demos_classic__data_catalogue_demo__metadata_docs_index', 'arguments': '{\"query\":\"4*3 in Python multiply 4 3 example code\"}'}}\n[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n{'type': 'response.output_item.done', 'item': {'type': 'function_call_output', 'call_id': 'call_oeVGufSLXyLhy2TWunj8LuIz', 'output': \"[{'page_content': '# SUPPLY_DB.WAREHOUSE.INVENTORY_SNAPSHOT\\\\n\\\\n## Business Description\\\\nTable SUPPLY_DB.WAREHOUSE.INVENTORY_SNAPSHOT contains 4 modeled columns and supports domain analytics for supply_db.\\\\n\\\\n## User Comment\\\\nDaily inventory levels by SKU and location\\\\n\\\\n## Columns\\\\nON_HAND_QTY: On hand inventory quantity LOCATION_ID: Warehouse location identifier SKU_ID: Stock keeping unit identifier SNAPSHOT_DATE: Daily snapshot date', 'metadata': {'doc_id': 'SUPPLY_DB.WAREHOUSE.INVENTORY_SNAPSHOT'}}, {'page_content': '# FINANCE_DB.GL.GENERAL_LEDGER\\\\n\\\\n## Business Description\\\\nTable FINANCE_DB.GL.GENERAL_LEDGER contains 4 modeled columns and supports domain analytics for finance_db.\\\\n\\\\n## User Comment\\\\nAccounting journal entries by period\\\\n\\\\n## Columns\\\\nAMOUNT_LOCAL: Transaction amount in local currency ACCOUNT_CODE: General ledger account code POSTING_DATE: Accounting posting date ENTRY_ID: Unique journal entry identifier', 'metadata': {'doc_id': 'FINANCE_DB.GL.GENERAL_LEDGER'}}, {'page_content': '# MARKETING_DB.ATTRIBUTION.CAMPAIGN_PERFORMANCE\\\\n\\\\n## Business Description\\\\nTable MARKETING_DB.ATTRIBUTION.CAMPAIGN_PERFORMANCE contains 4 modeled columns and supports domain analytics for marketing_db.\\\\n\\\\n## User Comment\\\\nCampaign performance by channel and date\\\\n\\\\n## Columns\\\\nSPEND_USD: Daily media spend in USD EVENT_DATE: Attribution event date CHANNEL: Marketing channel CAMPAIGN_ID: Campaign identifier', 'metadata': {'doc_id': 'MARKETING_DB.ATTRIBUTION.CAMPAIGN_PERFORMANCE'}}, {'page_content': '# FINANCE_DB.AP.INVOICES\\\\n\\\\n## Business Description\\\\nTable FINANCE_DB.AP.INVOICES contains 4 modeled columns and supports domain analytics for finance_db.\\\\n\\\\n## User Comment\\\\nAccounts payable invoices from ERP\\\\n\\\\n## Columns\\\\nINVOICE_TOTAL: Total invoice value INVOICE_DATE: Invoice issue date SUPPLIER_ID: Supplier identifier INVOICE_ID: Unique supplier invoice ID', 'metadata': {'doc_id': 'FINANCE_DB.AP.INVOICES'}}, {'page_content': '# SALES_DB.CRM.OPPORTUNITIES\\\\n\\\\n## Business Description\\\\nTable SALES_DB.CRM.OPPORTUNITIES contains 4 modeled columns and supports domain analytics for sales_db.\\\\n\\\\n## User Comment\\\\nSales opportunities and pipeline status\\\\n\\\\n## Columns\\\\nEXPECTED_ARR: Expected annual recurring revenue STAGE: Current sales stage ACCOUNT_ID: Foreign key to account OPPORTUNITY_ID: Sales opportunity ID', 'metadata': {'doc_id': 'SALES_DB.CRM.OPPORTUNITIES'}}]\"}}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ''}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': 'In'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' Python'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ','}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '4'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' *'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '3'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' evaluates'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' to'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '12'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '.\\n\\n'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': 'Example'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ':\\n'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '-'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' In'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' the'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' interpreter'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ':'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' >>>'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '4'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' *'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '3'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '\\n'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '12'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '\\n\\n'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': 'If'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' you'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' want'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' to'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' assign'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' it'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ':'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' result'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' ='}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '4'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' *'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '3'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' #'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' result'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' is'}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': ' '}\n{'type': 'response.output_text.delta', 'item_id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'delta': '12'}\n{'type': 'response.output_item.done', 'item': {'id': 'chatcmpl-D9OZVRAQbnjkWcrpUlV4DtQi7lcAV', 'content': [{'text': 'In Python, 4 * 3 evaluates to 12.\\n\\nExample:\\n- In the interpreter: >>> 4 * 3\\n  12\\n\\nIf you want to assign it: result = 4 * 3  # result is 12', 'type': 'output_text'}], 'role': 'assistant', 'type': 'message'}}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "{\"trace_id\": \"tr-5832dada0411b07a6ba5c8e7343b48ae\", \"sql_warehouse_id\": null}",
      "text/plain": [
       "Trace(trace_id=tr-5832dada0411b07a6ba5c8e7343b48ae)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for chunk in AGENT.predict_stream(\n",
    "    {\"input\": [{\"role\": \"user\", \"content\": \"What is 4*3 in Python?\"}], \"custom_inputs\": {\"session_id\": \"test-session-123\"}}\n",
    "):\n",
    "    print(chunk.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4a1b30d-d079-49e6-9d54-caf1b31ad79b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log the `agent` as an MLflow model\n",
    "Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "- **TODO**: If your Unity Catalog Function queries a [vector search index](https://docs.databricks.com/generative-ai/agent-framework/unstructured-retrieval-tools.html) or leverages [external functions](https://docs.databricks.com/generative-ai/agent-framework/external-connection-tools.html), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See [docs](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough) for more details.\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab75aac6-d7be-484f-a3ea-73835e1c5dcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b60e646a-3470-471e-8410-0bfe666485e5/lib/python3.10/site-packages/databricks/connect/session.py:451: UserWarning: Ignoring the default notebook Spark session and creating a new Spark Connect session. To use the default notebook Spark session, use DatabricksSession.builder.getOrCreate() with no additional parameters.\n  warnings.warn(new_notebook_session_msg)\n\uD83D\uDD17 View Logged Model at: https://fe-vm-vdm-classic-eq33dc.cloud.databricks.com/ml/experiments/2681661749963311/models/m-6ac37e5f5fbd4d35887dcc9befa1d3cc?o=1453025918090624\n2026/02/15 05:10:44 INFO mlflow.pyfunc: Predicting on input example to validate output\n2026/02/15 05:10:44 WARNING mlflow.tracing.fluent: No active trace found. Please create a span using `mlflow.start_span` or `@mlflow.trace` before calling `mlflow.update_current_trace`.\n2026/02/15 05:10:44 WARNING mlflow.tracing.fluent: Failed to start span predict_stream: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n2026/02/15 05:10:44 WARNING mlflow.tracing.fluent: No active trace found. Please create a span using `mlflow.start_span` or `@mlflow.trace` before calling `mlflow.update_current_trace`.\n2026/02/15 05:10:44 WARNING mlflow.tracing.fluent: Failed to start span Completions: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/15 05:10:44 WARNING mlflow.tracing.fluent: Failed to start span Completions: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n2026/02/15 05:10:49 WARNING mlflow.tracing.fluent: No active trace found. Please create a span using `mlflow.start_span` or `@mlflow.trace` before calling `mlflow.update_current_trace`.\n2026/02/15 05:10:49 WARNING mlflow.tracing.fluent: Failed to start span predict_stream: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n2026/02/15 05:10:49 WARNING mlflow.tracing.fluent: No active trace found. Please create a span using `mlflow.start_span` or `@mlflow.trace` before calling `mlflow.update_current_trace`.\n2026/02/15 05:10:49 WARNING mlflow.tracing.fluent: Failed to start span Completions: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/15 05:10:50 WARNING mlflow.tracing.fluent: Failed to start span Completions: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n"
     ]
    }
   ],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import LLM_ENDPOINT_NAME, VECTOR_SEARCH_TOOLS, uc_toolkit\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "for tool in VECTOR_SEARCH_TOOLS:\n",
    "    resources.extend(tool.resources)\n",
    "for tool in uc_toolkit.tools:\n",
    "    # TODO: If the UC function includes dependencies like external connection or vector search, please include them manually.\n",
    "    # See the TODO in the markdown above for more information.\n",
    "    udf_name = tool.get(\"function\", {}).get(\"name\", \"\").replace(\"__\", \".\")\n",
    "    resources.append(DatabricksFunction(function_name=udf_name))\n",
    "\n",
    "input_example = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"crm\"\n",
    "        }\n",
    "    ],\n",
    "    \"custom_inputs\": {\n",
    "        \"session_id\": \"test-session\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            \"databricks-openai\",\n",
    "            \"backoff\",\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4ffd99d-0773-4ab6-a766-ef9586155274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with [Agent Evaluation](https://docs.databricks.com/mlflow3/genai/eval-monitor)\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics.\n",
    "\n",
    "Evaluate your agent with one of our [predefined LLM scorers](https://docs.databricks.com/mlflow3/genai/eval-monitor/predefined-judge-scorers), or try adding [custom metrics](https://docs.databricks.com/mlflow3/genai/eval-monitor/custom-scorers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "823900a9-6281-457d-8ab8-14fd8e92860a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 12"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/15 05:12:50 INFO mlflow.genai.utils.data_validation: Testing model prediction with the first sample in the dataset. To disable this check, set the MLFLOW_GENAI_EVAL_SKIP_TRACE_VALIDATION environment variable to True.\n2026/02/15 05:12:50 WARNING mlflow.tracing.fluent: No active trace found. Please create a span using `mlflow.start_span` or `@mlflow.trace` before calling `mlflow.update_current_trace`.\n2026/02/15 05:12:50 WARNING mlflow.tracing.fluent: Failed to start span predict_stream: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n2026/02/15 05:12:50 WARNING mlflow.tracing.fluent: No active trace found. Please create a span using `mlflow.start_span` or `@mlflow.trace` before calling `mlflow.update_current_trace`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ac5f1ebcdb4a22a6c3e888e1b14ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [Elapsed: 00:00, Remaining: ?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <title>Evaluation output</title>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "\n",
       "        .header {\n",
       "            a.button {\n",
       "                padding: 4px 8px;\n",
       "                line-height: 20px;\n",
       "                box-shadow: none;\n",
       "                height: 20px;\n",
       "                display: inline-flex;\n",
       "                align-items: center;\n",
       "                justify-content: center;\n",
       "                vertical-align: middle;\n",
       "                background-color: rgb(34, 114, 180);\n",
       "                color: rgb(255, 255, 255);\n",
       "                text-decoration: none;\n",
       "                animation-duration: 0s;\n",
       "                transition: none 0s ease 0s;\n",
       "                position: relative;\n",
       "                white-space: nowrap;\n",
       "                text-align: center;\n",
       "                border: 1px solid rgb(192, 205, 216);\n",
       "                cursor: pointer;\n",
       "                user-select: none;\n",
       "                touch-action: manipulation;\n",
       "                border-radius: 4px;\n",
       "                gap: 6px;\n",
       "            }\n",
       "\n",
       "            a.button:hover {\n",
       "                background-color: rgb(14, 83, 139) !important;\n",
       "                border-color: transparent !important;\n",
       "                color: rgb(255, 255, 255) !important;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .warnings-section {\n",
       "            margin-top: 8px;\n",
       "\n",
       "            ul {\n",
       "                list-style-type: none;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .instructions-section {\n",
       "            margin-top: 16px;\n",
       "            font-size: 14px;\n",
       "\n",
       "            ul {\n",
       "                margin-top: 0;\n",
       "                margin-bottom: 0;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        code {\n",
       "            font-family: monospace;\n",
       "        }\n",
       "\n",
       "        .note {\n",
       "            color: #666;\n",
       "        }\n",
       "\n",
       "        a {\n",
       "            color: #2272B4;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "\n",
       "        a:hover {\n",
       "            color: #005580;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "    <div class=\"header\">\n",
       "        <a href=\"https://fe-vm-vdm-classic-eq33dc.cloud.databricks.com/ml/experiments/2681661749963311/evaluation-runs?selectedRunUuid=69f3fa53e4b34ecba963b4f7d13727a8\" class=\"button\">\n",
       "            View evaluation results in MLflow\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1em\" height=\"1em\" fill=\"none\" viewBox=\"0 0 16 16\" aria-hidden=\"true\" focusable=\"false\" class=\"\">\n",
       "                <path fill=\"currentColor\" d=\"M10 1h5v5h-1.5V3.56L8.53 8.53 7.47 7.47l4.97-4.97H10z\"></path>\n",
       "                <path fill=\"currentColor\" d=\"M1 2.75A.75.75 0 0 1 1.75 2H8v1.5H2.5v10h10V8H14v6.25a.75.75 0 0 1-.75.75H1.75a.75.75 0 0 1-.75-.75z\"></path>\n",
       "            </svg>\n",
       "        </a>\n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness, Correctness\n",
    "\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Show me all tables related to CRM and sales opportunities\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"should include the SALES_DB.CRM.OPPORTUNITIES table and related CRM tables\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda input: AGENT.predict({\"input\": input, \"custom_inputs\": {\"session_id\": \"evaluation-session\"}}),\n",
    "    scorers=[\n",
    "        RelevanceToQuery(),           # Response addresses the query\n",
    "        Safety(),                      # No harmful content\n",
    "        Correctness(),                 # Matches expected response\n",
    "        RetrievalRelevance(),          # Retrieved docs are relevant\n",
    "        RetrievalGroundedness()        # Response grounded in retrieved context\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Review the evaluation results in the MLfLow UI (see console output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4c15720-5aa2-4f4d-8c58-8c8253c67483",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Perform pre-deployment validation of the agent\n",
    "Before registering and deploying the agent, we perform pre-deployment checks via the [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API. See [documentation](https://docs.databricks.com/machine-learning/model-serving/model-serving-debug.html#validate-inputs) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8792365f-6612-4e96-8e2e-3e5796dbfab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645d720ac9c5405b807cbb865fe7774e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e9c02ab849436da5ea3b251fabafb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/15 05:14:12 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4adb375ae4c42eeb011185215b77dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5381e7bfa34aeab35b9281d27b6263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/15 05:14:16 INFO mlflow.utils.virtualenv: Creating a new environment in /tmp/virtualenv_envs/mlflow-d30267116563d0a39185d9dff5c80b4fd4aa1a25 with python version 3.10.12 using uv\nUsing CPython 3.10.12 interpreter at: \u001B[36m/usr/bin/python3.10\u001B[39m\nCreating virtual environment at: \u001B[36m/tmp/virtualenv_envs/mlflow-d30267116563d0a39185d9dff5c80b4fd4aa1a25\u001B[39m\nActivate with: \u001B[32msource /tmp/virtualenv_envs/mlflow-d30267116563d0a39185d9dff5c80b4fd4aa1a25/bin/activate\u001B[39m\n2026/02/15 05:14:17 INFO mlflow.utils.virtualenv: Installing dependencies\n\u001B[2mUsing Python 3.10.12 environment at: /tmp/virtualenv_envs/mlflow-d30267116563d0a39185d9dff5c80b4fd4aa1a25\u001B[0m\n\u001B[2mResolved \u001B[1m3 packages\u001B[0m \u001B[2min 34ms\u001B[0m\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pip \u001B[2m(2.0MiB)\u001B[0m\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pip\n\u001B[2mPrepared \u001B[1m3 packages\u001B[0m \u001B[2min 104ms\u001B[0m\u001B[0m\n\u001B[2mInstalled \u001B[1m3 packages\u001B[0m \u001B[2min 18ms\u001B[0m\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpip\u001B[0m\u001B[2m==22.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msetuptools\u001B[0m\u001B[2m==82.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwheel\u001B[0m\u001B[2m==0.38.4\u001B[0m\n\u001B[2mUsing Python 3.10.12 environment at: /tmp/virtualenv_envs/mlflow-d30267116563d0a39185d9dff5c80b4fd4aa1a25\u001B[0m\n\u001B[2mResolved \u001B[1m150 packages\u001B[0m \u001B[2min 923ms\u001B[0m\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-tracing \u001B[2m(1.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m grpcio \u001B[2m(6.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m kiwisolver \u001B[2m(1.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pillow \u001B[2m(6.7MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow \u001B[2m(9.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m zstandard \u001B[2m(5.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m sqlalchemy \u001B[2m(3.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m openai \u001B[2m(1.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-skinny \u001B[2m(2.7MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m fonttools \u001B[2m(4.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m tiktoken \u001B[2m(1.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m numpy \u001B[2m(17.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m scipy \u001B[2m(35.9MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pandas \u001B[2m(12.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m aiohttp \u001B[2m(1.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m scikit-learn \u001B[2m(9.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pydantic-core \u001B[2m(2.0MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pyarrow \u001B[2m(45.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m cryptography \u001B[2m(4.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m matplotlib \u001B[2m(8.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m databricks-connect \u001B[2m(2.3MiB)\u001B[0m\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m tiktoken\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m kiwisolver\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m aiohttp\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pydantic-core\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m mlflow-tracing\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m databricks-connect\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m sqlalchemy\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m cryptography\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m zstandard\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m fonttools\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pillow\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m grpcio\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m openai\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m mlflow-skinny\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m matplotlib\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m numpy\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m scikit-learn\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m mlflow\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pyarrow\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pandas\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m scipy\n\u001B[2mPrepared \u001B[1m149 packages\u001B[0m \u001B[2min 3.23s\u001B[0m\u001B[0m\n\u001B[2mInstalled \u001B[1m149 packages\u001B[0m \u001B[2min 320ms\u001B[0m\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohappyeyeballs\u001B[0m\u001B[2m==2.6.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohttp\u001B[0m\u001B[2m==3.13.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohttp-retry\u001B[0m\u001B[2m==2.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiosignal\u001B[0m\u001B[2m==1.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1malembic\u001B[0m\u001B[2m==1.18.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mannotated-doc\u001B[0m\u001B[2m==0.0.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mannotated-types\u001B[0m\u001B[2m==0.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1manyio\u001B[0m\u001B[2m==4.12.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1masync-timeout\u001B[0m\u001B[2m==5.0.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mattrs\u001B[0m\u001B[2m==25.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mbackoff\u001B[0m\u001B[2m==2.2.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mblinker\u001B[0m\u001B[2m==1.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcachetools\u001B[0m\u001B[2m==6.2.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcertifi\u001B[0m\u001B[2m==2026.1.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcffi\u001B[0m\u001B[2m==2.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcharset-normalizer\u001B[0m\u001B[2m==3.4.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mclick\u001B[0m\u001B[2m==8.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcloudpickle\u001B[0m\u001B[2m==3.1.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcolorama\u001B[0m\u001B[2m==0.4.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcontourpy\u001B[0m\u001B[2m==1.3.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcryptography\u001B[0m\u001B[2m==46.0.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcycler\u001B[0m\u001B[2m==0.12.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-ai-bridge\u001B[0m\u001B[2m==0.14.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-connect\u001B[0m\u001B[2m==16.1.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-mcp\u001B[0m\u001B[2m==0.8.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-openai\u001B[0m\u001B[2m==0.11.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-sdk\u001B[0m\u001B[2m==0.88.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-vectorsearch\u001B[0m\u001B[2m==0.65\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdeprecation\u001B[0m\u001B[2m==2.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdistro\u001B[0m\u001B[2m==1.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdocker\u001B[0m\u001B[2m==7.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mexceptiongroup\u001B[0m\u001B[2m==1.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfastapi\u001B[0m\u001B[2m==0.129.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mflask\u001B[0m\u001B[2m==3.1.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mflask-cors\u001B[0m\u001B[2m==6.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfonttools\u001B[0m\u001B[2m==4.61.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfrozenlist\u001B[0m\u001B[2m==1.8.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgitdb\u001B[0m\u001B[2m==4.0.12\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgitpython\u001B[0m\u001B[2m==3.1.46\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgoogle-auth\u001B[0m\u001B[2m==2.48.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgoogleapis-common-protos\u001B[0m\u001B[2m==1.72.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphene\u001B[0m\u001B[2m==3.4.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphql-core\u001B[0m\u001B[2m==3.2.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphql-relay\u001B[0m\u001B[2m==3.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgreenlet\u001B[0m\u001B[2m==3.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgriffe\u001B[0m\u001B[2m==1.15.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgrpcio\u001B[0m\u001B[2m==1.78.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgrpcio-status\u001B[0m\u001B[2m==1.78.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgunicorn\u001B[0m\u001B[2m==23.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mh11\u001B[0m\u001B[2m==0.16.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpcore\u001B[0m\u001B[2m==1.0.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpx\u001B[0m\u001B[2m==0.28.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpx-sse\u001B[0m\u001B[2m==0.4.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhuey\u001B[0m\u001B[2m==2.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1midna\u001B[0m\u001B[2m==3.11\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mimportlib-metadata\u001B[0m\u001B[2m==8.7.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mitsdangerous\u001B[0m\u001B[2m==2.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjinja2\u001B[0m\u001B[2m==3.1.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjiter\u001B[0m\u001B[2m==0.13.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjoblib\u001B[0m\u001B[2m==1.5.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonpatch\u001B[0m\u001B[2m==1.33\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonpointer\u001B[0m\u001B[2m==3.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonschema\u001B[0m\u001B[2m==4.26.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonschema-specifications\u001B[0m\u001B[2m==2025.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mkiwisolver\u001B[0m\u001B[2m==1.4.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain\u001B[0m\u001B[2m==1.2.10\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-core\u001B[0m\u001B[2m==1.2.12\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph\u001B[0m\u001B[2m==1.0.8\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-checkpoint\u001B[0m\u001B[2m==4.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-prebuilt\u001B[0m\u001B[2m==1.0.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-sdk\u001B[0m\u001B[2m==0.3.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangsmith\u001B[0m\u001B[2m==0.7.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmako\u001B[0m\u001B[2m==1.3.10\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmarkupsafe\u001B[0m\u001B[2m==3.0.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmatplotlib\u001B[0m\u001B[2m==3.10.8\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmcp\u001B[0m\u001B[2m==1.26.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow\u001B[0m\u001B[2m==3.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow-skinny\u001B[0m\u001B[2m==3.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow-tracing\u001B[0m\u001B[2m==3.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmultidict\u001B[0m\u001B[2m==6.7.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnest-asyncio\u001B[0m\u001B[2m==1.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnumpy\u001B[0m\u001B[2m==1.26.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopenai\u001B[0m\u001B[2m==2.21.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopenai-agents\u001B[0m\u001B[2m==0.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-api\u001B[0m\u001B[2m==1.39.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-proto\u001B[0m\u001B[2m==1.39.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-sdk\u001B[0m\u001B[2m==1.39.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-semantic-conventions\u001B[0m\u001B[2m==0.60b1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1morjson\u001B[0m\u001B[2m==3.11.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mormsgpack\u001B[0m\u001B[2m==1.12.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpackaging\u001B[0m\u001B[2m==25.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpandas\u001B[0m\u001B[2m==2.3.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpillow\u001B[0m\u001B[2m==12.1.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mprettytable\u001B[0m\u001B[2m==3.17.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpropcache\u001B[0m\u001B[2m==0.4.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mprotobuf\u001B[0m\u001B[2m==6.33.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpy4j\u001B[0m\u001B[2m==0.10.9.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyarrow\u001B[0m\u001B[2m==22.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyasn1\u001B[0m\u001B[2m==0.6.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyasn1-modules\u001B[0m\u001B[2m==0.4.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpycparser\u001B[0m\u001B[2m==3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic\u001B[0m\u001B[2m==2.12.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic-core\u001B[0m\u001B[2m==2.41.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic-settings\u001B[0m\u001B[2m==2.12.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyjwt\u001B[0m\u001B[2m==2.11.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyparsing\u001B[0m\u001B[2m==3.3.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-dateutil\u001B[0m\u001B[2m==2.9.0.post0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-dotenv\u001B[0m\u001B[2m==1.2.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-multipart\u001B[0m\u001B[2m==0.0.22\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpytz\u001B[0m\u001B[2m==2025.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyyaml\u001B[0m\u001B[2m==6.0.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mreferencing\u001B[0m\u001B[2m==0.37.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mregex\u001B[0m\u001B[2m==2026.1.15\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrequests\u001B[0m\u001B[2m==2.32.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrequests-toolbelt\u001B[0m\u001B[2m==1.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrpds-py\u001B[0m\u001B[2m==0.30.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrsa\u001B[0m\u001B[2m==4.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mscikit-learn\u001B[0m\u001B[2m==1.7.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mscipy\u001B[0m\u001B[2m==1.15.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msix\u001B[0m\u001B[2m==1.17.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mskops\u001B[0m\u001B[2m==0.13.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msmmap\u001B[0m\u001B[2m==5.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msniffio\u001B[0m\u001B[2m==1.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msqlalchemy\u001B[0m\u001B[2m==2.0.46\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msqlparse\u001B[0m\u001B[2m==0.5.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msse-starlette\u001B[0m\u001B[2m==3.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mstarlette\u001B[0m\u001B[2m==0.52.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtabulate\u001B[0m\u001B[2m==0.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtenacity\u001B[0m\u001B[2m==9.1.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mthreadpoolctl\u001B[0m\u001B[2m==3.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtiktoken\u001B[0m\u001B[2m==0.12.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtomli\u001B[0m\u001B[2m==2.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtqdm\u001B[0m\u001B[2m==4.67.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtypes-requests\u001B[0m\u001B[2m==2.32.4.20260107\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-extensions\u001B[0m\u001B[2m==4.15.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-inspection\u001B[0m\u001B[2m==0.4.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtzdata\u001B[0m\u001B[2m==2025.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1munitycatalog-ai\u001B[0m\u001B[2m==0.3.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1munitycatalog-client\u001B[0m\u001B[2m==0.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1munitycatalog-openai\u001B[0m\u001B[2m==0.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1murllib3\u001B[0m\u001B[2m==2.6.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1muuid-utils\u001B[0m\u001B[2m==0.14.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1muvicorn\u001B[0m\u001B[2m==0.40.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwcwidth\u001B[0m\u001B[2m==0.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwerkzeug\u001B[0m\u001B[2m==3.1.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mxxhash\u001B[0m\u001B[2m==3.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1myarl\u001B[0m\u001B[2m==1.22.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mzipp\u001B[0m\u001B[2m==3.23.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mzstandard\u001B[0m\u001B[2m==0.25.0\u001B[0m\n2026/02/15 05:14:22 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-d30267116563d0a39185d9dff5c80b4fd4aa1a25/bin/activate && python -c \"\"']'\n2026/02/15 05:14:22 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-d30267116563d0a39185d9dff5c80b4fd4aa1a25/bin/activate && python /local_disk0/.ephemeral_nfs/envs/pythonEnv-b60e646a-3470-471e-8410-0bfe666485e5/lib/python3.10/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///local_disk0/user_tmp_data/spark-b60e646a-3470-471e-8410-0b/tmp4ywyt8dd/agent --content-type json --input-path /local_disk0/user_tmp_data/spark-b60e646a-3470-471e-8410-0b/tmp0qpd2v2i/input.json']'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n{\"object\": \"response\", \"output\": [{\"type\": \"function_call\", \"id\": \"chatcmpl-D9OkisEcSGzKQnBebynW4i7hvOyfq\", \"call_id\": \"call_qfnX0fHq5tcpqlwyoeXw9llb\", \"name\": \"jack_demos_classic__data_catalogue_demo__metadata_docs_index\", \"arguments\": \"{\\\"query\\\":\\\"hello\\\"}\"}, {\"type\": \"function_call_output\", \"call_id\": \"call_qfnX0fHq5tcpqlwyoeXw9llb\", \"output\": \"[{'page_content': '# SALES_DB.CRM.OPPORTUNITIES\\\\n\\\\n## Business Description\\\\nTable SALES_DB.CRM.OPPORTUNITIES contains 4 modeled columns and supports domain analytics for sales_db.\\\\n\\\\n## User Comment\\\\nSales opportunities and pipeline status\\\\n\\\\n## Columns\\\\nEXPECTED_ARR: Expected annual recurring revenue STAGE: Current sales stage ACCOUNT_ID: Foreign key to account OPPORTUNITY_ID: Sales opportunity ID', 'metadata': {'doc_id': 'SALES_DB.CRM.OPPORTUNITIES'}}, {'page_content': '# SALES_DB.CRM.ACCOUNTS\\\\n\\\\n## Business Description\\\\nTable SALES_DB.CRM.ACCOUNTS contains 3 modeled columns and supports domain analytics for sales_db.\\\\n\\\\n## User Comment\\\\nCustomer accounts and segmentation attributes\\\\n\\\\n## Columns\\\\nSEGMENT: Commercial segment classification ACCOUNT_NAME: Customer legal name ACCOUNT_ID: Account identifier', 'metadata': {'doc_id': 'SALES_DB.CRM.ACCOUNTS'}}, {'page_content': '# FINANCE_DB.GL.GENERAL_LEDGER\\\\n\\\\n## Business Description\\\\nTable FINANCE_DB.GL.GENERAL_LEDGER contains 4 modeled columns and supports domain analytics for finance_db.\\\\n\\\\n## User Comment\\\\nAccounting journal entries by period\\\\n\\\\n## Columns\\\\nAMOUNT_LOCAL: Transaction amount in local currency ACCOUNT_CODE: General ledger account code POSTING_DATE: Accounting posting date ENTRY_ID: Unique journal entry identifier', 'metadata': {'doc_id': 'FINANCE_DB.GL.GENERAL_LEDGER'}}, {'page_content': '# FINANCE_DB.AP.INVOICES\\\\n\\\\n## Business Description\\\\nTable FINANCE_DB.AP.INVOICES contains 4 modeled columns and supports domain analytics for finance_db.\\\\n\\\\n## User Comment\\\\nAccounts payable invoices from ERP\\\\n\\\\n## Columns\\\\nINVOICE_TOTAL: Total invoice value INVOICE_DATE: Invoice issue date SUPPLIER_ID: Supplier identifier INVOICE_ID: Unique supplier invoice ID', 'metadata': {'doc_id': 'FINANCE_DB.AP.INVOICES'}}, {'page_content': '# SUPPLY_DB.WAREHOUSE.INVENTORY_SNAPSHOT\\\\n\\\\n## Business Description\\\\nTable SUPPLY_DB.WAREHOUSE.INVENTORY_SNAPSHOT contains 4 modeled columns and supports domain analytics for supply_db.\\\\n\\\\n## User Comment\\\\nDaily inventory levels by SKU and location\\\\n\\\\n## Columns\\\\nON_HAND_QTY: On hand inventory quantity LOCATION_ID: Warehouse location identifier SKU_ID: Stock keeping unit identifier SNAPSHOT_DATE: Daily snapshot date', 'metadata': {'doc_id': 'SUPPLY_DB.WAREHOUSE.INVENTORY_SNAPSHOT'}}]\"}, {\"type\": \"message\", \"id\": \"chatcmpl-D9Okjvlm15qhobBCvxD7VIdVuhsMR\", \"content\": [{\"text\": \"Hello! How can I help you today? If you'd like, I can search the data catalogue for tables or metadata\\u2014tell me what you're looking for (e.g., accounts, invoices, inventory, opportunities) and I'll return related tables and details.\", \"type\": \"output_text\"}], \"role\": \"assistant\"}], \"custom_outputs\": {\"session_id\": \"validation-session\"}}"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/15 05:14:34 INFO mlflow.tracing.export.async_export_queue: Flushing the async trace logging queue before program exit. This may take a while...\n"
     ]
    }
   ],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"input\": [{\"role\": \"user\", \"content\": \"Hello!\"}], \"custom_inputs\": {\"session_id\": \"validation-session\"}},\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "746c9832-d34e-4df6-b5b2-2f8e54ce268d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12e0c87f-e475-4b22-bf4a-c4fafc24817e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'jack_demos_classic.data_catalogue_demo.catalog_rag_agent'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2003b7a1cd5b4c60b644c5265a321633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50d39e072f84466875b3f50b32d6d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '1' of model 'jack_demos_classic.data_catalogue_demo.catalog_rag_agent': https://fe-vm-vdm-classic-eq33dc.cloud.databricks.com/explore/data/models/jack_demos_classic/data_catalogue_demo/catalog_rag_agent/version/1?o=1453025918090624\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"jack_demos_classic\"\n",
    "schema = \"data_catalogue_demo\"\n",
    "model_name = \"catalog_rag_agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9f4a3f1-dc1a-468b-96bc-2ec9389d2fb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "891fcb2a-d28a-4393-bdc6-8098b8514308",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b44bd773a3146e1ad26bb16a5b02234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b60e646a-3470-471e-8410-0bfe666485e5/lib/python3.10/site-packages/databricks/agents/deployments.py:641: UserWarning: This endpoint is being deployed without a feedback model, which has been deprecated.\nFor more information, see: https://docs.databricks.com/aws/en/generative-ai/agent-framework/feedback-model\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n    Deployment of jack_demos_classic.data_catalogue_demo.catalog_rag_agent version 1 initiated.  This can take up to 15 minutes and the Review App & Query Endpoint will not work until this deployment finishes.\n\n    View status: https://fe-vm-vdm-classic-eq33dc.cloud.databricks.com/ml/endpoints/agents_jack_demos_classic-data_catalogue_demo-catalog_rag_agent/?o=1453025918090624\n    Review App: https://fe-vm-vdm-classic-eq33dc.cloud.databricks.com/ml/review-v2/46b81ce779bf40b1a1efe718e9a08dde/chat?o=1453025918090624\n\nYou can refer back to the links above from the endpoint detail page at https://fe-vm-vdm-classic-eq33dc.cloud.databricks.com/ml/endpoints/agents_jack_demos_classic-data_catalogue_demo-catalog_rag_agent/?o=1453025918090624.\n\nTo set up monitoring for your deployed agent, see:\nhttps://docs.databricks.com/aws/en/mlflow3/genai/eval-monitor/production-monitoring\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Deployment(model_name='jack_demos_classic.data_catalogue_demo.catalog_rag_agent', model_version='1', endpoint_name='agents_jack_demos_classic-data_catalogue_demo-catalog_rag_agent', served_entity_name='jack_demos_classic-data_catalogue_demo-catalog_rag_agent_1', query_endpoint='https://fe-vm-vdm-classic-eq33dc.cloud.databricks.com/serving-endpoints/agents_jack_demos_classic-data_catalogue_demo-catalog_rag_agent/served-models/jack_demos_classic-data_catalogue_demo-catalog_rag_agent_1/invocations?o=1453025918090624', endpoint_url='https://fe-vm-vdm-classic-eq33dc.cloud.databricks.com/ml/endpoints/agents_jack_demos_classic-data_catalogue_demo-catalog_rag_agent/?o=1453025918090624', review_app_url='https://fe-vm-vdm-classic-eq33dc.cloud.databricks.com/ml/review-v2/46b81ce779bf40b1a1efe718e9a08dde/chat?o=1453025918090624')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from databricks import agents\n",
    "# NOTE: pass scale_to_zero=True to agents.deploy() to enable scale-to-zero for cost savings.\n",
    "# This is not recommended for production workloads, as capacity is not guaranteed when scaled to zero.\n",
    "# Scaled to zero endpoints may take extra time to respond when queried, while they scale back up.\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version, tags = {\"endpointSource\": \"playground\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e360dbb-d1cc-49c0-b018-fb3bfa9bd059",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See [docs](https://docs.databricks.com/generative-ai/deploy-agent.html) for details"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "driver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}